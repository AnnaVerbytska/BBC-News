{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79627a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.jsonl')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ad60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna_verbytska/Documents/BBC-News-Sentiment-GenAI/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sentences  \\\n",
      "0  When the government announced it had reached i...   \n",
      "1  Palestinian leader Mahmoud Abbas has said Tony...   \n",
      "2  Tony Blair does not believe abortion should be...   \n",
      "3  Tony Blair called it Tony Blair's \" masochism ...   \n",
      "4  Tory shadow home secretary David Davis warned ...   \n",
      "\n",
      "                                   entity_sentiments  \n",
      "0  {'Tony': {'sentiment': 'neutral', 'confidence'...  \n",
      "1  {'Tony': {'sentiment': 'positive', 'confidence...  \n",
      "2  {'Tony': {'sentiment': 'neutral', 'confidence'...  \n",
      "3  {'Tony': {'sentiment': 'negative', 'confidence...  \n",
      "4  {'Tony': {'sentiment': 'negative', 'confidence...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"../data/filtered_sentences.csv\")\n",
    "\n",
    "# Load model and tokenizer (disable fast tokenizer to avoid SentencePiece issue)\n",
    "model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the target entities\n",
    "entities = [\"Tony\", \"Blair\", \"Tony Blair\"]\n",
    "\n",
    "# Function to get sentiment for a given entity in a sentence\n",
    "def get_sentiment(sentence, entity):\n",
    "    # Required input format: [CLS] entity [SEP] sentence [SEP]\n",
    "    formatted_input = f\"[CLS] {entity} [SEP] {sentence} [SEP]\"\n",
    "    encoded_input = tokenizer(formatted_input, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "        probs = softmax(output.logits, dim=1).cpu().numpy()[0]\n",
    "        sentiment_labels = [\"Negative\", \"Neutral\", \"Postitive\"]\n",
    "        return sentiment_labels[probs.argmax()], round(float(probs.max()), 3)\n",
    "\n",
    "# Function to analyze all sentences for all entities\n",
    "def analyze_entities(df, entities):\n",
    "    sentiment_results = []\n",
    "\n",
    "    for sentence in df[\"sentences\"]:\n",
    "        entity_sentiments = {}\n",
    "        for entity in entities:\n",
    "            if entity in sentence:\n",
    "                sentiment, confidence = get_sentiment(sentence, entity)\n",
    "                entity_sentiments[entity] = {\"sentiment\": sentiment, \"confidence\": confidence}\n",
    "        sentiment_results.append(entity_sentiments)\n",
    "\n",
    "    df[\"entity_sentiments\"] = sentiment_results\n",
    "    return df\n",
    "\n",
    "# Run the analysis\n",
    "df = analyze_entities(df, entities)\n",
    "\n",
    "# Output the result\n",
    "print(df[[\"sentences\", \"entity_sentiments\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b562d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f90d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
